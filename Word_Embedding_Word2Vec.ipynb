{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embedding - Word2Vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7p-ww7SpNhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9d5d7c24-29e8-4c72-8862-a1ffb8e715a5"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "import re"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqMImqqHpTed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    # obtains tokens with a least 1 alphabet\n",
        "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
        "    return pattern.findall(text.lower())\n",
        "\n",
        "def mapping(tokens):\n",
        "    word_to_id = dict()\n",
        "    id_to_word = dict()\n",
        "\n",
        "    for i, token in enumerate(set(tokens)):\n",
        "        word_to_id[token] = i\n",
        "        id_to_word[i] = token\n",
        "\n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "def generate_training_data(tokens, word_to_id, window_size):\n",
        "    N = len(tokens)\n",
        "    X, Y = [], []\n",
        "\n",
        "    for i in range(N):\n",
        "        nbr_inds = list(range(max(0, i - window_size), i)) + \\\n",
        "                   list(range(i + 1, min(N, i + window_size + 1)))\n",
        "        #print(nbr_inds)\n",
        "        for j in nbr_inds:\n",
        "            #print(tokens[j],\" \",word_to_id[tokens[j]])\n",
        "            X.append(word_to_id[tokens[i]])\n",
        "            Y.append(word_to_id[tokens[j]])\n",
        "            \n",
        "    X = np.array(X)\n",
        "    X = np.expand_dims(X, axis=0)\n",
        "    Y = np.array(Y)\n",
        "    Y = np.expand_dims(Y, axis=0)\n",
        "            \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxQRyNa3pZFL",
        "colab_type": "code",
        "outputId": "0f5e78a2-4152-4e07-b2fc-f6fc06381050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18683
        }
      },
      "source": [
        "doc = \"The people who do the work in America have never been invisible to the Democratic Party. It is time to make the American Dream real for them again. We need a government that stands up for the hopes, values, and interests of working people, and gives everyone willing to work hard the chance to make the most of their God-given potential. In platform hearings around the country, Americans reaffirmed our belief that this great nation can compete–and succeed–in the 21st Century but only if we take a new approach. One that is both innovative and faithful to the basic economic principles that made this country great. We Democrats want–and we hereby pledge–a government led by Barack Obama that looks out for families in the new economy with health care, retirement security, and help, especially in bad times. Investment in our country–in energy, education, infrastructure, science. A ladder of opportunity for all. Democrats see these as the pillars of a more competitive and fair economy that will allow all Americans to take advantage of the opportunities of our new era.\"\n",
        "tokens = tokenize(doc)\n",
        "word_to_id, id_to_word = mapping(tokens)\n",
        "X, Y = generate_training_data(tokens, word_to_id, 3)\n",
        "\n",
        "for i in range(len(X[0])):\n",
        "  print(id_to_word[X[0][i]],\" \",id_to_word[Y[0][i]])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the   people\n",
            "the   who\n",
            "the   do\n",
            "people   the\n",
            "people   who\n",
            "people   do\n",
            "people   the\n",
            "who   the\n",
            "who   people\n",
            "who   do\n",
            "who   the\n",
            "who   work\n",
            "do   the\n",
            "do   people\n",
            "do   who\n",
            "do   the\n",
            "do   work\n",
            "do   in\n",
            "the   people\n",
            "the   who\n",
            "the   do\n",
            "the   work\n",
            "the   in\n",
            "the   america\n",
            "work   who\n",
            "work   do\n",
            "work   the\n",
            "work   in\n",
            "work   america\n",
            "work   have\n",
            "in   do\n",
            "in   the\n",
            "in   work\n",
            "in   america\n",
            "in   have\n",
            "in   never\n",
            "america   the\n",
            "america   work\n",
            "america   in\n",
            "america   have\n",
            "america   never\n",
            "america   been\n",
            "have   work\n",
            "have   in\n",
            "have   america\n",
            "have   never\n",
            "have   been\n",
            "have   invisible\n",
            "never   in\n",
            "never   america\n",
            "never   have\n",
            "never   been\n",
            "never   invisible\n",
            "never   to\n",
            "been   america\n",
            "been   have\n",
            "been   never\n",
            "been   invisible\n",
            "been   to\n",
            "been   the\n",
            "invisible   have\n",
            "invisible   never\n",
            "invisible   been\n",
            "invisible   to\n",
            "invisible   the\n",
            "invisible   democratic\n",
            "to   never\n",
            "to   been\n",
            "to   invisible\n",
            "to   the\n",
            "to   democratic\n",
            "to   party\n",
            "the   been\n",
            "the   invisible\n",
            "the   to\n",
            "the   democratic\n",
            "the   party\n",
            "the   it\n",
            "democratic   invisible\n",
            "democratic   to\n",
            "democratic   the\n",
            "democratic   party\n",
            "democratic   it\n",
            "democratic   is\n",
            "party   to\n",
            "party   the\n",
            "party   democratic\n",
            "party   it\n",
            "party   is\n",
            "party   time\n",
            "it   the\n",
            "it   democratic\n",
            "it   party\n",
            "it   is\n",
            "it   time\n",
            "it   to\n",
            "is   democratic\n",
            "is   party\n",
            "is   it\n",
            "is   time\n",
            "is   to\n",
            "is   make\n",
            "time   party\n",
            "time   it\n",
            "time   is\n",
            "time   to\n",
            "time   make\n",
            "time   the\n",
            "to   it\n",
            "to   is\n",
            "to   time\n",
            "to   make\n",
            "to   the\n",
            "to   american\n",
            "make   is\n",
            "make   time\n",
            "make   to\n",
            "make   the\n",
            "make   american\n",
            "make   dream\n",
            "the   time\n",
            "the   to\n",
            "the   make\n",
            "the   american\n",
            "the   dream\n",
            "the   real\n",
            "american   to\n",
            "american   make\n",
            "american   the\n",
            "american   dream\n",
            "american   real\n",
            "american   for\n",
            "dream   make\n",
            "dream   the\n",
            "dream   american\n",
            "dream   real\n",
            "dream   for\n",
            "dream   them\n",
            "real   the\n",
            "real   american\n",
            "real   dream\n",
            "real   for\n",
            "real   them\n",
            "real   again\n",
            "for   american\n",
            "for   dream\n",
            "for   real\n",
            "for   them\n",
            "for   again\n",
            "for   we\n",
            "them   dream\n",
            "them   real\n",
            "them   for\n",
            "them   again\n",
            "them   we\n",
            "them   need\n",
            "again   real\n",
            "again   for\n",
            "again   them\n",
            "again   we\n",
            "again   need\n",
            "again   a\n",
            "we   for\n",
            "we   them\n",
            "we   again\n",
            "we   need\n",
            "we   a\n",
            "we   government\n",
            "need   them\n",
            "need   again\n",
            "need   we\n",
            "need   a\n",
            "need   government\n",
            "need   that\n",
            "a   again\n",
            "a   we\n",
            "a   need\n",
            "a   government\n",
            "a   that\n",
            "a   stands\n",
            "government   we\n",
            "government   need\n",
            "government   a\n",
            "government   that\n",
            "government   stands\n",
            "government   up\n",
            "that   need\n",
            "that   a\n",
            "that   government\n",
            "that   stands\n",
            "that   up\n",
            "that   for\n",
            "stands   a\n",
            "stands   government\n",
            "stands   that\n",
            "stands   up\n",
            "stands   for\n",
            "stands   the\n",
            "up   government\n",
            "up   that\n",
            "up   stands\n",
            "up   for\n",
            "up   the\n",
            "up   hopes\n",
            "for   that\n",
            "for   stands\n",
            "for   up\n",
            "for   the\n",
            "for   hopes\n",
            "for   values\n",
            "the   stands\n",
            "the   up\n",
            "the   for\n",
            "the   hopes\n",
            "the   values\n",
            "the   and\n",
            "hopes   up\n",
            "hopes   for\n",
            "hopes   the\n",
            "hopes   values\n",
            "hopes   and\n",
            "hopes   interests\n",
            "values   for\n",
            "values   the\n",
            "values   hopes\n",
            "values   and\n",
            "values   interests\n",
            "values   of\n",
            "and   the\n",
            "and   hopes\n",
            "and   values\n",
            "and   interests\n",
            "and   of\n",
            "and   working\n",
            "interests   hopes\n",
            "interests   values\n",
            "interests   and\n",
            "interests   of\n",
            "interests   working\n",
            "interests   people\n",
            "of   values\n",
            "of   and\n",
            "of   interests\n",
            "of   working\n",
            "of   people\n",
            "of   and\n",
            "working   and\n",
            "working   interests\n",
            "working   of\n",
            "working   people\n",
            "working   and\n",
            "working   gives\n",
            "people   interests\n",
            "people   of\n",
            "people   working\n",
            "people   and\n",
            "people   gives\n",
            "people   everyone\n",
            "and   of\n",
            "and   working\n",
            "and   people\n",
            "and   gives\n",
            "and   everyone\n",
            "and   willing\n",
            "gives   working\n",
            "gives   people\n",
            "gives   and\n",
            "gives   everyone\n",
            "gives   willing\n",
            "gives   to\n",
            "everyone   people\n",
            "everyone   and\n",
            "everyone   gives\n",
            "everyone   willing\n",
            "everyone   to\n",
            "everyone   work\n",
            "willing   and\n",
            "willing   gives\n",
            "willing   everyone\n",
            "willing   to\n",
            "willing   work\n",
            "willing   hard\n",
            "to   gives\n",
            "to   everyone\n",
            "to   willing\n",
            "to   work\n",
            "to   hard\n",
            "to   the\n",
            "work   everyone\n",
            "work   willing\n",
            "work   to\n",
            "work   hard\n",
            "work   the\n",
            "work   chance\n",
            "hard   willing\n",
            "hard   to\n",
            "hard   work\n",
            "hard   the\n",
            "hard   chance\n",
            "hard   to\n",
            "the   to\n",
            "the   work\n",
            "the   hard\n",
            "the   chance\n",
            "the   to\n",
            "the   make\n",
            "chance   work\n",
            "chance   hard\n",
            "chance   the\n",
            "chance   to\n",
            "chance   make\n",
            "chance   the\n",
            "to   hard\n",
            "to   the\n",
            "to   chance\n",
            "to   make\n",
            "to   the\n",
            "to   most\n",
            "make   the\n",
            "make   chance\n",
            "make   to\n",
            "make   the\n",
            "make   most\n",
            "make   of\n",
            "the   chance\n",
            "the   to\n",
            "the   make\n",
            "the   most\n",
            "the   of\n",
            "the   their\n",
            "most   to\n",
            "most   make\n",
            "most   the\n",
            "most   of\n",
            "most   their\n",
            "most   god\n",
            "of   make\n",
            "of   the\n",
            "of   most\n",
            "of   their\n",
            "of   god\n",
            "of   given\n",
            "their   the\n",
            "their   most\n",
            "their   of\n",
            "their   god\n",
            "their   given\n",
            "their   potential\n",
            "god   most\n",
            "god   of\n",
            "god   their\n",
            "god   given\n",
            "god   potential\n",
            "god   in\n",
            "given   of\n",
            "given   their\n",
            "given   god\n",
            "given   potential\n",
            "given   in\n",
            "given   platform\n",
            "potential   their\n",
            "potential   god\n",
            "potential   given\n",
            "potential   in\n",
            "potential   platform\n",
            "potential   hearings\n",
            "in   god\n",
            "in   given\n",
            "in   potential\n",
            "in   platform\n",
            "in   hearings\n",
            "in   around\n",
            "platform   given\n",
            "platform   potential\n",
            "platform   in\n",
            "platform   hearings\n",
            "platform   around\n",
            "platform   the\n",
            "hearings   potential\n",
            "hearings   in\n",
            "hearings   platform\n",
            "hearings   around\n",
            "hearings   the\n",
            "hearings   country\n",
            "around   in\n",
            "around   platform\n",
            "around   hearings\n",
            "around   the\n",
            "around   country\n",
            "around   americans\n",
            "the   platform\n",
            "the   hearings\n",
            "the   around\n",
            "the   country\n",
            "the   americans\n",
            "the   reaffirmed\n",
            "country   hearings\n",
            "country   around\n",
            "country   the\n",
            "country   americans\n",
            "country   reaffirmed\n",
            "country   our\n",
            "americans   around\n",
            "americans   the\n",
            "americans   country\n",
            "americans   reaffirmed\n",
            "americans   our\n",
            "americans   belief\n",
            "reaffirmed   the\n",
            "reaffirmed   country\n",
            "reaffirmed   americans\n",
            "reaffirmed   our\n",
            "reaffirmed   belief\n",
            "reaffirmed   that\n",
            "our   country\n",
            "our   americans\n",
            "our   reaffirmed\n",
            "our   belief\n",
            "our   that\n",
            "our   this\n",
            "belief   americans\n",
            "belief   reaffirmed\n",
            "belief   our\n",
            "belief   that\n",
            "belief   this\n",
            "belief   great\n",
            "that   reaffirmed\n",
            "that   our\n",
            "that   belief\n",
            "that   this\n",
            "that   great\n",
            "that   nation\n",
            "this   our\n",
            "this   belief\n",
            "this   that\n",
            "this   great\n",
            "this   nation\n",
            "this   can\n",
            "great   belief\n",
            "great   that\n",
            "great   this\n",
            "great   nation\n",
            "great   can\n",
            "great   compete\n",
            "nation   that\n",
            "nation   this\n",
            "nation   great\n",
            "nation   can\n",
            "nation   compete\n",
            "nation   and\n",
            "can   this\n",
            "can   great\n",
            "can   nation\n",
            "can   compete\n",
            "can   and\n",
            "can   succeed\n",
            "compete   great\n",
            "compete   nation\n",
            "compete   can\n",
            "compete   and\n",
            "compete   succeed\n",
            "compete   in\n",
            "and   nation\n",
            "and   can\n",
            "and   compete\n",
            "and   succeed\n",
            "and   in\n",
            "and   the\n",
            "succeed   can\n",
            "succeed   compete\n",
            "succeed   and\n",
            "succeed   in\n",
            "succeed   the\n",
            "succeed   21st\n",
            "in   compete\n",
            "in   and\n",
            "in   succeed\n",
            "in   the\n",
            "in   21st\n",
            "in   century\n",
            "the   and\n",
            "the   succeed\n",
            "the   in\n",
            "the   21st\n",
            "the   century\n",
            "the   but\n",
            "21st   succeed\n",
            "21st   in\n",
            "21st   the\n",
            "21st   century\n",
            "21st   but\n",
            "21st   only\n",
            "century   in\n",
            "century   the\n",
            "century   21st\n",
            "century   but\n",
            "century   only\n",
            "century   if\n",
            "but   the\n",
            "but   21st\n",
            "but   century\n",
            "but   only\n",
            "but   if\n",
            "but   we\n",
            "only   21st\n",
            "only   century\n",
            "only   but\n",
            "only   if\n",
            "only   we\n",
            "only   take\n",
            "if   century\n",
            "if   but\n",
            "if   only\n",
            "if   we\n",
            "if   take\n",
            "if   a\n",
            "we   but\n",
            "we   only\n",
            "we   if\n",
            "we   take\n",
            "we   a\n",
            "we   new\n",
            "take   only\n",
            "take   if\n",
            "take   we\n",
            "take   a\n",
            "take   new\n",
            "take   approach\n",
            "a   if\n",
            "a   we\n",
            "a   take\n",
            "a   new\n",
            "a   approach\n",
            "a   one\n",
            "new   we\n",
            "new   take\n",
            "new   a\n",
            "new   approach\n",
            "new   one\n",
            "new   that\n",
            "approach   take\n",
            "approach   a\n",
            "approach   new\n",
            "approach   one\n",
            "approach   that\n",
            "approach   is\n",
            "one   a\n",
            "one   new\n",
            "one   approach\n",
            "one   that\n",
            "one   is\n",
            "one   both\n",
            "that   new\n",
            "that   approach\n",
            "that   one\n",
            "that   is\n",
            "that   both\n",
            "that   innovative\n",
            "is   approach\n",
            "is   one\n",
            "is   that\n",
            "is   both\n",
            "is   innovative\n",
            "is   and\n",
            "both   one\n",
            "both   that\n",
            "both   is\n",
            "both   innovative\n",
            "both   and\n",
            "both   faithful\n",
            "innovative   that\n",
            "innovative   is\n",
            "innovative   both\n",
            "innovative   and\n",
            "innovative   faithful\n",
            "innovative   to\n",
            "and   is\n",
            "and   both\n",
            "and   innovative\n",
            "and   faithful\n",
            "and   to\n",
            "and   the\n",
            "faithful   both\n",
            "faithful   innovative\n",
            "faithful   and\n",
            "faithful   to\n",
            "faithful   the\n",
            "faithful   basic\n",
            "to   innovative\n",
            "to   and\n",
            "to   faithful\n",
            "to   the\n",
            "to   basic\n",
            "to   economic\n",
            "the   and\n",
            "the   faithful\n",
            "the   to\n",
            "the   basic\n",
            "the   economic\n",
            "the   principles\n",
            "basic   faithful\n",
            "basic   to\n",
            "basic   the\n",
            "basic   economic\n",
            "basic   principles\n",
            "basic   that\n",
            "economic   to\n",
            "economic   the\n",
            "economic   basic\n",
            "economic   principles\n",
            "economic   that\n",
            "economic   made\n",
            "principles   the\n",
            "principles   basic\n",
            "principles   economic\n",
            "principles   that\n",
            "principles   made\n",
            "principles   this\n",
            "that   basic\n",
            "that   economic\n",
            "that   principles\n",
            "that   made\n",
            "that   this\n",
            "that   country\n",
            "made   economic\n",
            "made   principles\n",
            "made   that\n",
            "made   this\n",
            "made   country\n",
            "made   great\n",
            "this   principles\n",
            "this   that\n",
            "this   made\n",
            "this   country\n",
            "this   great\n",
            "this   we\n",
            "country   that\n",
            "country   made\n",
            "country   this\n",
            "country   great\n",
            "country   we\n",
            "country   democrats\n",
            "great   made\n",
            "great   this\n",
            "great   country\n",
            "great   we\n",
            "great   democrats\n",
            "great   want\n",
            "we   this\n",
            "we   country\n",
            "we   great\n",
            "we   democrats\n",
            "we   want\n",
            "we   and\n",
            "democrats   country\n",
            "democrats   great\n",
            "democrats   we\n",
            "democrats   want\n",
            "democrats   and\n",
            "democrats   we\n",
            "want   great\n",
            "want   we\n",
            "want   democrats\n",
            "want   and\n",
            "want   we\n",
            "want   hereby\n",
            "and   we\n",
            "and   democrats\n",
            "and   want\n",
            "and   we\n",
            "and   hereby\n",
            "and   pledge\n",
            "we   democrats\n",
            "we   want\n",
            "we   and\n",
            "we   hereby\n",
            "we   pledge\n",
            "we   a\n",
            "hereby   want\n",
            "hereby   and\n",
            "hereby   we\n",
            "hereby   pledge\n",
            "hereby   a\n",
            "hereby   government\n",
            "pledge   and\n",
            "pledge   we\n",
            "pledge   hereby\n",
            "pledge   a\n",
            "pledge   government\n",
            "pledge   led\n",
            "a   we\n",
            "a   hereby\n",
            "a   pledge\n",
            "a   government\n",
            "a   led\n",
            "a   by\n",
            "government   hereby\n",
            "government   pledge\n",
            "government   a\n",
            "government   led\n",
            "government   by\n",
            "government   barack\n",
            "led   pledge\n",
            "led   a\n",
            "led   government\n",
            "led   by\n",
            "led   barack\n",
            "led   obama\n",
            "by   a\n",
            "by   government\n",
            "by   led\n",
            "by   barack\n",
            "by   obama\n",
            "by   that\n",
            "barack   government\n",
            "barack   led\n",
            "barack   by\n",
            "barack   obama\n",
            "barack   that\n",
            "barack   looks\n",
            "obama   led\n",
            "obama   by\n",
            "obama   barack\n",
            "obama   that\n",
            "obama   looks\n",
            "obama   out\n",
            "that   by\n",
            "that   barack\n",
            "that   obama\n",
            "that   looks\n",
            "that   out\n",
            "that   for\n",
            "looks   barack\n",
            "looks   obama\n",
            "looks   that\n",
            "looks   out\n",
            "looks   for\n",
            "looks   families\n",
            "out   obama\n",
            "out   that\n",
            "out   looks\n",
            "out   for\n",
            "out   families\n",
            "out   in\n",
            "for   that\n",
            "for   looks\n",
            "for   out\n",
            "for   families\n",
            "for   in\n",
            "for   the\n",
            "families   looks\n",
            "families   out\n",
            "families   for\n",
            "families   in\n",
            "families   the\n",
            "families   new\n",
            "in   out\n",
            "in   for\n",
            "in   families\n",
            "in   the\n",
            "in   new\n",
            "in   economy\n",
            "the   for\n",
            "the   families\n",
            "the   in\n",
            "the   new\n",
            "the   economy\n",
            "the   with\n",
            "new   families\n",
            "new   in\n",
            "new   the\n",
            "new   economy\n",
            "new   with\n",
            "new   health\n",
            "economy   in\n",
            "economy   the\n",
            "economy   new\n",
            "economy   with\n",
            "economy   health\n",
            "economy   care\n",
            "with   the\n",
            "with   new\n",
            "with   economy\n",
            "with   health\n",
            "with   care\n",
            "with   retirement\n",
            "health   new\n",
            "health   economy\n",
            "health   with\n",
            "health   care\n",
            "health   retirement\n",
            "health   security\n",
            "care   economy\n",
            "care   with\n",
            "care   health\n",
            "care   retirement\n",
            "care   security\n",
            "care   and\n",
            "retirement   with\n",
            "retirement   health\n",
            "retirement   care\n",
            "retirement   security\n",
            "retirement   and\n",
            "retirement   help\n",
            "security   health\n",
            "security   care\n",
            "security   retirement\n",
            "security   and\n",
            "security   help\n",
            "security   especially\n",
            "and   care\n",
            "and   retirement\n",
            "and   security\n",
            "and   help\n",
            "and   especially\n",
            "and   in\n",
            "help   retirement\n",
            "help   security\n",
            "help   and\n",
            "help   especially\n",
            "help   in\n",
            "help   bad\n",
            "especially   security\n",
            "especially   and\n",
            "especially   help\n",
            "especially   in\n",
            "especially   bad\n",
            "especially   times\n",
            "in   and\n",
            "in   help\n",
            "in   especially\n",
            "in   bad\n",
            "in   times\n",
            "in   investment\n",
            "bad   help\n",
            "bad   especially\n",
            "bad   in\n",
            "bad   times\n",
            "bad   investment\n",
            "bad   in\n",
            "times   especially\n",
            "times   in\n",
            "times   bad\n",
            "times   investment\n",
            "times   in\n",
            "times   our\n",
            "investment   in\n",
            "investment   bad\n",
            "investment   times\n",
            "investment   in\n",
            "investment   our\n",
            "investment   country\n",
            "in   bad\n",
            "in   times\n",
            "in   investment\n",
            "in   our\n",
            "in   country\n",
            "in   in\n",
            "our   times\n",
            "our   investment\n",
            "our   in\n",
            "our   country\n",
            "our   in\n",
            "our   energy\n",
            "country   investment\n",
            "country   in\n",
            "country   our\n",
            "country   in\n",
            "country   energy\n",
            "country   education\n",
            "in   in\n",
            "in   our\n",
            "in   country\n",
            "in   energy\n",
            "in   education\n",
            "in   infrastructure\n",
            "energy   our\n",
            "energy   country\n",
            "energy   in\n",
            "energy   education\n",
            "energy   infrastructure\n",
            "energy   science\n",
            "education   country\n",
            "education   in\n",
            "education   energy\n",
            "education   infrastructure\n",
            "education   science\n",
            "education   a\n",
            "infrastructure   in\n",
            "infrastructure   energy\n",
            "infrastructure   education\n",
            "infrastructure   science\n",
            "infrastructure   a\n",
            "infrastructure   ladder\n",
            "science   energy\n",
            "science   education\n",
            "science   infrastructure\n",
            "science   a\n",
            "science   ladder\n",
            "science   of\n",
            "a   education\n",
            "a   infrastructure\n",
            "a   science\n",
            "a   ladder\n",
            "a   of\n",
            "a   opportunity\n",
            "ladder   infrastructure\n",
            "ladder   science\n",
            "ladder   a\n",
            "ladder   of\n",
            "ladder   opportunity\n",
            "ladder   for\n",
            "of   science\n",
            "of   a\n",
            "of   ladder\n",
            "of   opportunity\n",
            "of   for\n",
            "of   all\n",
            "opportunity   a\n",
            "opportunity   ladder\n",
            "opportunity   of\n",
            "opportunity   for\n",
            "opportunity   all\n",
            "opportunity   democrats\n",
            "for   ladder\n",
            "for   of\n",
            "for   opportunity\n",
            "for   all\n",
            "for   democrats\n",
            "for   see\n",
            "all   of\n",
            "all   opportunity\n",
            "all   for\n",
            "all   democrats\n",
            "all   see\n",
            "all   these\n",
            "democrats   opportunity\n",
            "democrats   for\n",
            "democrats   all\n",
            "democrats   see\n",
            "democrats   these\n",
            "democrats   as\n",
            "see   for\n",
            "see   all\n",
            "see   democrats\n",
            "see   these\n",
            "see   as\n",
            "see   the\n",
            "these   all\n",
            "these   democrats\n",
            "these   see\n",
            "these   as\n",
            "these   the\n",
            "these   pillars\n",
            "as   democrats\n",
            "as   see\n",
            "as   these\n",
            "as   the\n",
            "as   pillars\n",
            "as   of\n",
            "the   see\n",
            "the   these\n",
            "the   as\n",
            "the   pillars\n",
            "the   of\n",
            "the   a\n",
            "pillars   these\n",
            "pillars   as\n",
            "pillars   the\n",
            "pillars   of\n",
            "pillars   a\n",
            "pillars   more\n",
            "of   as\n",
            "of   the\n",
            "of   pillars\n",
            "of   a\n",
            "of   more\n",
            "of   competitive\n",
            "a   the\n",
            "a   pillars\n",
            "a   of\n",
            "a   more\n",
            "a   competitive\n",
            "a   and\n",
            "more   pillars\n",
            "more   of\n",
            "more   a\n",
            "more   competitive\n",
            "more   and\n",
            "more   fair\n",
            "competitive   of\n",
            "competitive   a\n",
            "competitive   more\n",
            "competitive   and\n",
            "competitive   fair\n",
            "competitive   economy\n",
            "and   a\n",
            "and   more\n",
            "and   competitive\n",
            "and   fair\n",
            "and   economy\n",
            "and   that\n",
            "fair   more\n",
            "fair   competitive\n",
            "fair   and\n",
            "fair   economy\n",
            "fair   that\n",
            "fair   will\n",
            "economy   competitive\n",
            "economy   and\n",
            "economy   fair\n",
            "economy   that\n",
            "economy   will\n",
            "economy   allow\n",
            "that   and\n",
            "that   fair\n",
            "that   economy\n",
            "that   will\n",
            "that   allow\n",
            "that   all\n",
            "will   fair\n",
            "will   economy\n",
            "will   that\n",
            "will   allow\n",
            "will   all\n",
            "will   americans\n",
            "allow   economy\n",
            "allow   that\n",
            "allow   will\n",
            "allow   all\n",
            "allow   americans\n",
            "allow   to\n",
            "all   that\n",
            "all   will\n",
            "all   allow\n",
            "all   americans\n",
            "all   to\n",
            "all   take\n",
            "americans   will\n",
            "americans   allow\n",
            "americans   all\n",
            "americans   to\n",
            "americans   take\n",
            "americans   advantage\n",
            "to   allow\n",
            "to   all\n",
            "to   americans\n",
            "to   take\n",
            "to   advantage\n",
            "to   of\n",
            "take   all\n",
            "take   americans\n",
            "take   to\n",
            "take   advantage\n",
            "take   of\n",
            "take   the\n",
            "advantage   americans\n",
            "advantage   to\n",
            "advantage   take\n",
            "advantage   of\n",
            "advantage   the\n",
            "advantage   opportunities\n",
            "of   to\n",
            "of   take\n",
            "of   advantage\n",
            "of   the\n",
            "of   opportunities\n",
            "of   of\n",
            "the   take\n",
            "the   advantage\n",
            "the   of\n",
            "the   opportunities\n",
            "the   of\n",
            "the   our\n",
            "opportunities   advantage\n",
            "opportunities   of\n",
            "opportunities   the\n",
            "opportunities   of\n",
            "opportunities   our\n",
            "opportunities   new\n",
            "of   of\n",
            "of   the\n",
            "of   opportunities\n",
            "of   our\n",
            "of   new\n",
            "of   era\n",
            "our   the\n",
            "our   opportunities\n",
            "our   of\n",
            "our   new\n",
            "our   era\n",
            "new   opportunities\n",
            "new   of\n",
            "new   our\n",
            "new   era\n",
            "era   of\n",
            "era   our\n",
            "era   new\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU6zPjWBpd5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(id_to_word)\n",
        "m = Y.shape[1]\n",
        "# turn Y into one hot encoding\n",
        "Y_one_hot = np.zeros((vocab_size, m))\n",
        "Y_one_hot[Y.flatten(), np.arange(m)] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxqNxzG8qbcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_wrd_emb(vocab_size, emb_size):\n",
        "    \"\"\"\n",
        "    vocab_size: int. vocabulary size of your corpus or training data\n",
        "    emb_size: int. word embedding size. How many dimensions to represent each vocabulary\n",
        "    \"\"\"\n",
        "    WRD_EMB = np.random.randn(vocab_size, emb_size) * 0.01\n",
        "    \n",
        "    assert(WRD_EMB.shape == (vocab_size, emb_size))\n",
        "    return WRD_EMB\n",
        "\n",
        "def initialize_dense(input_size, output_size):\n",
        "    \"\"\"\n",
        "    input_size: int. size of the input to the dense layer\n",
        "    output_szie: int. size of the output out of the dense layer\n",
        "    \"\"\"\n",
        "    W = np.random.randn(output_size, input_size) * 0.01\n",
        "    \n",
        "    assert(W.shape == (output_size, input_size))\n",
        "    return W\n",
        "\n",
        "def initialize_parameters(vocab_size, emb_size):\n",
        "    WRD_EMB = initialize_wrd_emb(vocab_size, emb_size)\n",
        "    W = initialize_dense(emb_size, vocab_size)\n",
        "    \n",
        "    parameters = {}\n",
        "    parameters['WRD_EMB'] = WRD_EMB\n",
        "    parameters['W'] = W\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSTYCKK6qe9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ind_to_word_vecs(inds, parameters):\n",
        "    \"\"\"\n",
        "    inds: numpy array. shape: (1, m)\n",
        "    parameters: dict. weights to be trained\n",
        "    \"\"\"\n",
        "    m = inds.shape[1]\n",
        "    WRD_EMB = parameters['WRD_EMB']\n",
        "    word_vec = WRD_EMB[inds.flatten(), :].T\n",
        "    \n",
        "    assert(word_vec.shape == (WRD_EMB.shape[1], m))\n",
        "    \n",
        "    return word_vec\n",
        "\n",
        "def linear_dense(word_vec, parameters):\n",
        "    \"\"\"\n",
        "    word_vec: numpy array. shape: (emb_size, m)\n",
        "    parameters: dict. weights to be trained\n",
        "    \"\"\"\n",
        "    m = word_vec.shape[1]\n",
        "    W = parameters['W']\n",
        "    Z = np.dot(W, word_vec)\n",
        "    \n",
        "    assert(Z.shape == (W.shape[0], m))\n",
        "    \n",
        "    return W, Z\n",
        "\n",
        "def softmax(Z):\n",
        "    \"\"\"\n",
        "    Z: output out of the dense layer. shape: (vocab_size, m)\n",
        "    \"\"\"\n",
        "    softmax_out = np.divide(np.exp(Z), np.sum(np.exp(Z), axis=0, keepdims=True) + 0.001)\n",
        "    \n",
        "    assert(softmax_out.shape == Z.shape)\n",
        "\n",
        "    return softmax_out\n",
        "\n",
        "def forward_propagation(inds, parameters):\n",
        "    word_vec = ind_to_word_vecs(inds, parameters)\n",
        "    W, Z = linear_dense(word_vec, parameters)\n",
        "    softmax_out = softmax(Z)\n",
        "    \n",
        "    caches = {}\n",
        "    caches['inds'] = inds\n",
        "    caches['word_vec'] = word_vec\n",
        "    caches['W'] = W\n",
        "    caches['Z'] = Z\n",
        "    \n",
        "    return softmax_out, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIHfgBMwueYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2023
        },
        "outputId": "7621d52f-29bb-402d-950a-25f2a038daef"
      },
      "source": [
        "id_to_word"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'basic',\n",
              " 1: 'values',\n",
              " 2: 'families',\n",
              " 3: 'made',\n",
              " 4: 'hereby',\n",
              " 5: 'energy',\n",
              " 6: 'in',\n",
              " 7: 'with',\n",
              " 8: 'advantage',\n",
              " 9: 'and',\n",
              " 10: 'is',\n",
              " 11: 'only',\n",
              " 12: 'american',\n",
              " 13: 'security',\n",
              " 14: 'work',\n",
              " 15: 'stands',\n",
              " 16: 'invisible',\n",
              " 17: 'more',\n",
              " 18: 'them',\n",
              " 19: 'most',\n",
              " 20: 'around',\n",
              " 21: 'will',\n",
              " 22: 'party',\n",
              " 23: 'economic',\n",
              " 24: 'pillars',\n",
              " 25: 'everyone',\n",
              " 26: 'interests',\n",
              " 27: 'as',\n",
              " 28: 'hearings',\n",
              " 29: 'competitive',\n",
              " 30: 'compete',\n",
              " 31: 'pledge',\n",
              " 32: 'take',\n",
              " 33: 'obama',\n",
              " 34: 'their',\n",
              " 35: 'democratic',\n",
              " 36: 'hopes',\n",
              " 37: 'the',\n",
              " 38: 'democrats',\n",
              " 39: 'god',\n",
              " 40: 'great',\n",
              " 41: 'these',\n",
              " 42: 'care',\n",
              " 43: 'opportunities',\n",
              " 44: 'who',\n",
              " 45: 'science',\n",
              " 46: 'this',\n",
              " 47: 'education',\n",
              " 48: 'era',\n",
              " 49: 'new',\n",
              " 50: 'hard',\n",
              " 51: 'but',\n",
              " 52: 'it',\n",
              " 53: 'that',\n",
              " 54: 'principles',\n",
              " 55: 'especially',\n",
              " 56: 'given',\n",
              " 57: 'have',\n",
              " 58: 'century',\n",
              " 59: 'see',\n",
              " 60: 'government',\n",
              " 61: '21st',\n",
              " 62: 'allow',\n",
              " 63: 'america',\n",
              " 64: 'time',\n",
              " 65: 'out',\n",
              " 66: 'barack',\n",
              " 67: 'help',\n",
              " 68: 'faithful',\n",
              " 69: 'again',\n",
              " 70: 'retirement',\n",
              " 71: 'working',\n",
              " 72: 'do',\n",
              " 73: 'never',\n",
              " 74: 'fair',\n",
              " 75: 'investment',\n",
              " 76: 'can',\n",
              " 77: 'want',\n",
              " 78: 'economy',\n",
              " 79: 'health',\n",
              " 80: 'infrastructure',\n",
              " 81: 'people',\n",
              " 82: 'real',\n",
              " 83: 'up',\n",
              " 84: 'approach',\n",
              " 85: 'need',\n",
              " 86: 'innovative',\n",
              " 87: 'bad',\n",
              " 88: 'times',\n",
              " 89: 'succeed',\n",
              " 90: 'led',\n",
              " 91: 'both',\n",
              " 92: 'gives',\n",
              " 93: 'belief',\n",
              " 94: 'our',\n",
              " 95: 'ladder',\n",
              " 96: 'a',\n",
              " 97: 'country',\n",
              " 98: 'make',\n",
              " 99: 'opportunity',\n",
              " 100: 'looks',\n",
              " 101: 'dream',\n",
              " 102: 'willing',\n",
              " 103: 'nation',\n",
              " 104: 'of',\n",
              " 105: 'chance',\n",
              " 106: 'platform',\n",
              " 107: 'reaffirmed',\n",
              " 108: 'been',\n",
              " 109: 'one',\n",
              " 110: 'all',\n",
              " 111: 'americans',\n",
              " 112: 'we',\n",
              " 113: 'to',\n",
              " 114: 'for',\n",
              " 115: 'potential',\n",
              " 116: 'by',\n",
              " 117: 'if'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3lUsF-cqiZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy(softmax_out, Y):\n",
        "    \"\"\"\n",
        "    softmax_out: output out of softmax. shape: (vocab_size, m)\n",
        "    \"\"\"\n",
        "    m = softmax_out.shape[1]\n",
        "    cost = -(1 / m) * np.sum(np.sum(Y * np.log(softmax_out + 0.001), axis=0, keepdims=True), axis=1)\n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVwQOEoKqlCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_backward(Y, softmax_out):\n",
        "    \"\"\"\n",
        "    Y: labels of training data. shape: (vocab_size, m)\n",
        "    softmax_out: output out of softmax. shape: (vocab_size, m)\n",
        "    \"\"\"\n",
        "    dL_dZ = softmax_out - Y\n",
        "    \n",
        "    assert(dL_dZ.shape == softmax_out.shape)\n",
        "    return dL_dZ\n",
        "\n",
        "def dense_backward(dL_dZ, caches):\n",
        "    \"\"\"\n",
        "    dL_dZ: shape: (vocab_size, m)\n",
        "    caches: dict. results from each steps of forward propagation\n",
        "    \"\"\"\n",
        "    W = caches['W']\n",
        "    word_vec = caches['word_vec']\n",
        "    m = word_vec.shape[1]\n",
        "    \n",
        "    dL_dW = (1 / m) * np.dot(dL_dZ, word_vec.T)\n",
        "    dL_dword_vec = np.dot(W.T, dL_dZ)\n",
        "\n",
        "    assert(W.shape == dL_dW.shape)\n",
        "    assert(word_vec.shape == dL_dword_vec.shape)\n",
        "    \n",
        "    return dL_dW, dL_dword_vec\n",
        "\n",
        "def backward_propagation(Y, softmax_out, caches):\n",
        "    dL_dZ = softmax_backward(Y, softmax_out)\n",
        "    dL_dW, dL_dword_vec = dense_backward(dL_dZ, caches)\n",
        "    \n",
        "    gradients = dict()\n",
        "    gradients['dL_dZ'] = dL_dZ\n",
        "    gradients['dL_dW'] = dL_dW\n",
        "    gradients['dL_dword_vec'] = dL_dword_vec\n",
        "    \n",
        "    return gradients\n",
        "\n",
        "def update_parameters(parameters, caches, gradients, learning_rate):\n",
        "    vocab_size, emb_size = parameters['WRD_EMB'].shape\n",
        "    inds = caches['inds']\n",
        "    dL_dword_vec = gradients['dL_dword_vec']\n",
        "    m = inds.shape[-1]\n",
        "    \n",
        "    parameters['WRD_EMB'][inds.flatten(), :] -= dL_dword_vec.T * learning_rate\n",
        "\n",
        "    parameters['W'] -= learning_rate * gradients['dL_dW']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LknkUAOtq1EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def skipgram_model_training(X, Y, vocab_size, emb_size, learning_rate, epochs, batch_size=256, parameters=None, print_cost=False, plot_cost=True):\n",
        "    costs = []\n",
        "    m = X.shape[1]\n",
        "    \n",
        "    if parameters is None:\n",
        "        parameters = initialize_parameters(vocab_size, emb_size)\n",
        "    \n",
        "    begin_time = datetime.now()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_cost = 0\n",
        "        batch_inds = list(range(0, m, batch_size))\n",
        "        np.random.shuffle(batch_inds)\n",
        "        for i in batch_inds:\n",
        "            X_batch = X[:, i:i+batch_size]\n",
        "            Y_batch = Y[:, i:i+batch_size]\n",
        "            #print(X_batch,\" \",Y_batch)\n",
        "            softmax_out, caches = forward_propagation(X_batch, parameters)\n",
        "            gradients = backward_propagation(Y_batch, softmax_out, caches)\n",
        "            update_parameters(parameters, caches, gradients, learning_rate)\n",
        "            cost = cross_entropy(softmax_out, Y_batch)\n",
        "            epoch_cost += np.squeeze(cost)\n",
        "            \n",
        "        costs.append(epoch_cost)\n",
        "        if print_cost and epoch % (epochs // 500) == 0:\n",
        "            print(\"Cost after epoch {}: {}\".format(epoch, epoch_cost))\n",
        "        if epoch % (epochs // 100) == 0:\n",
        "            learning_rate *= 0.98\n",
        "    end_time = datetime.now()\n",
        "    print('training time: {}'.format(end_time - begin_time))\n",
        "            \n",
        "    if plot_cost:\n",
        "        plt.plot(np.arange(epochs), costs)\n",
        "        plt.xlabel('# of epochs')\n",
        "        plt.ylabel('cost')\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeCvJJYHq305",
        "colab_type": "code",
        "outputId": "11469d3d-3879-4a4c-b6e9-3c741c0d901b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8800
        }
      },
      "source": [
        "paras = skipgram_model_training(X, Y_one_hot, vocab_size, 100, 0.05, 5000, batch_size=128, parameters=None, print_cost=True)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 41.93248325993858\n",
            "Cost after epoch 10: 41.92547701688615\n",
            "Cost after epoch 20: 41.91749626704366\n",
            "Cost after epoch 30: 41.90743093120123\n",
            "Cost after epoch 40: 41.89398200942526\n",
            "Cost after epoch 50: 41.87546358979166\n",
            "Cost after epoch 60: 41.85010783746925\n",
            "Cost after epoch 70: 41.814852940919984\n",
            "Cost after epoch 80: 41.76560695918764\n",
            "Cost after epoch 90: 41.69682821348009\n",
            "Cost after epoch 100: 41.6015498565584\n",
            "Cost after epoch 110: 41.47339537202148\n",
            "Cost after epoch 120: 41.30294370354353\n",
            "Cost after epoch 130: 41.08812714560456\n",
            "Cost after epoch 140: 40.835327465021706\n",
            "Cost after epoch 150: 40.554533330502245\n",
            "Cost after epoch 160: 40.24934161926137\n",
            "Cost after epoch 170: 39.92578145536904\n",
            "Cost after epoch 180: 39.59881320392692\n",
            "Cost after epoch 190: 39.27998007591924\n",
            "Cost after epoch 200: 38.96557068974978\n",
            "Cost after epoch 210: 38.65185656480979\n",
            "Cost after epoch 220: 38.3308157653814\n",
            "Cost after epoch 230: 37.99027615038602\n",
            "Cost after epoch 240: 37.63827913222295\n",
            "Cost after epoch 250: 37.27342281317043\n",
            "Cost after epoch 260: 36.90418715609401\n",
            "Cost after epoch 270: 36.533328376838966\n",
            "Cost after epoch 280: 36.167609942420455\n",
            "Cost after epoch 290: 35.8003674419998\n",
            "Cost after epoch 300: 35.44315313598348\n",
            "Cost after epoch 310: 35.094894516711165\n",
            "Cost after epoch 320: 34.760742361243295\n",
            "Cost after epoch 330: 34.437517422422665\n",
            "Cost after epoch 340: 34.12393433669488\n",
            "Cost after epoch 350: 33.819494559333265\n",
            "Cost after epoch 360: 33.53394580566379\n",
            "Cost after epoch 370: 33.26485555531353\n",
            "Cost after epoch 380: 33.00729201033054\n",
            "Cost after epoch 390: 32.763626765691974\n",
            "Cost after epoch 400: 32.53545303758411\n",
            "Cost after epoch 410: 32.31601845443748\n",
            "Cost after epoch 420: 32.119251964729735\n",
            "Cost after epoch 430: 31.934405784430137\n",
            "Cost after epoch 440: 31.766315603468797\n",
            "Cost after epoch 450: 31.594511552850808\n",
            "Cost after epoch 460: 31.445207515295177\n",
            "Cost after epoch 470: 31.30847406801754\n",
            "Cost after epoch 480: 31.172709927014\n",
            "Cost after epoch 490: 31.054306319627393\n",
            "Cost after epoch 500: 30.94288983019657\n",
            "Cost after epoch 510: 30.831675569749827\n",
            "Cost after epoch 520: 30.747495592619874\n",
            "Cost after epoch 530: 30.658624204513917\n",
            "Cost after epoch 540: 30.579219988224274\n",
            "Cost after epoch 550: 30.50305593576416\n",
            "Cost after epoch 560: 30.431108117840843\n",
            "Cost after epoch 570: 30.368277490335785\n",
            "Cost after epoch 580: 30.316933862137823\n",
            "Cost after epoch 590: 30.25592265584074\n",
            "Cost after epoch 600: 30.215184685383385\n",
            "Cost after epoch 610: 30.163983682280943\n",
            "Cost after epoch 620: 30.130144047322865\n",
            "Cost after epoch 630: 30.08784500035571\n",
            "Cost after epoch 640: 30.048019677286106\n",
            "Cost after epoch 650: 30.0092511469544\n",
            "Cost after epoch 660: 29.972977078758813\n",
            "Cost after epoch 670: 29.944575397965046\n",
            "Cost after epoch 680: 29.91156980295945\n",
            "Cost after epoch 690: 29.875770986399807\n",
            "Cost after epoch 700: 29.84680801154488\n",
            "Cost after epoch 710: 29.811602744559124\n",
            "Cost after epoch 720: 29.784094265502734\n",
            "Cost after epoch 730: 29.7582300223801\n",
            "Cost after epoch 740: 29.7302260034757\n",
            "Cost after epoch 750: 29.708415695509956\n",
            "Cost after epoch 760: 29.676159935139005\n",
            "Cost after epoch 770: 29.652357012289986\n",
            "Cost after epoch 780: 29.632828168050448\n",
            "Cost after epoch 790: 29.605687279051086\n",
            "Cost after epoch 800: 29.592610962180583\n",
            "Cost after epoch 810: 29.572584164951387\n",
            "Cost after epoch 820: 29.54707192752752\n",
            "Cost after epoch 830: 29.527869000660917\n",
            "Cost after epoch 840: 29.51394816939817\n",
            "Cost after epoch 850: 29.49616140505391\n",
            "Cost after epoch 860: 29.48434361068751\n",
            "Cost after epoch 870: 29.466825894466258\n",
            "Cost after epoch 880: 29.461209314043515\n",
            "Cost after epoch 890: 29.449324793805307\n",
            "Cost after epoch 900: 29.43383306028287\n",
            "Cost after epoch 910: 29.42522208730505\n",
            "Cost after epoch 920: 29.412617400316915\n",
            "Cost after epoch 930: 29.407875181808613\n",
            "Cost after epoch 940: 29.406423372633625\n",
            "Cost after epoch 950: 29.40223469776049\n",
            "Cost after epoch 960: 29.392820583402372\n",
            "Cost after epoch 970: 29.3871864569227\n",
            "Cost after epoch 980: 29.38068249529147\n",
            "Cost after epoch 990: 29.38738108878579\n",
            "Cost after epoch 1000: 29.378627519110495\n",
            "Cost after epoch 1010: 29.380771483112262\n",
            "Cost after epoch 1020: 29.382368165620672\n",
            "Cost after epoch 1030: 29.38457897445231\n",
            "Cost after epoch 1040: 29.377233590945437\n",
            "Cost after epoch 1050: 29.378659700140407\n",
            "Cost after epoch 1060: 29.374645478402968\n",
            "Cost after epoch 1070: 29.388377304516922\n",
            "Cost after epoch 1080: 29.38117530649207\n",
            "Cost after epoch 1090: 29.39246402158828\n",
            "Cost after epoch 1100: 29.386186163913926\n",
            "Cost after epoch 1110: 29.391349690044343\n",
            "Cost after epoch 1120: 29.393537620190294\n",
            "Cost after epoch 1130: 29.399276994830537\n",
            "Cost after epoch 1140: 29.39124548673959\n",
            "Cost after epoch 1150: 29.397324494782666\n",
            "Cost after epoch 1160: 29.395517156090357\n",
            "Cost after epoch 1170: 29.398819250147874\n",
            "Cost after epoch 1180: 29.393168866348542\n",
            "Cost after epoch 1190: 29.39190447912658\n",
            "Cost after epoch 1200: 29.390297600190518\n",
            "Cost after epoch 1210: 29.40016981232685\n",
            "Cost after epoch 1220: 29.392770127987713\n",
            "Cost after epoch 1230: 29.396283945657416\n",
            "Cost after epoch 1240: 29.393195737161022\n",
            "Cost after epoch 1250: 29.387791854975948\n",
            "Cost after epoch 1260: 29.3846537489305\n",
            "Cost after epoch 1270: 29.387231742317027\n",
            "Cost after epoch 1280: 29.381556446039234\n",
            "Cost after epoch 1290: 29.37699207490223\n",
            "Cost after epoch 1300: 29.37939888389708\n",
            "Cost after epoch 1310: 29.37372000056944\n",
            "Cost after epoch 1320: 29.373147057692258\n",
            "Cost after epoch 1330: 29.359820392908883\n",
            "Cost after epoch 1340: 29.35645107186525\n",
            "Cost after epoch 1350: 29.363947605873506\n",
            "Cost after epoch 1360: 29.35168591540476\n",
            "Cost after epoch 1370: 29.34489141883403\n",
            "Cost after epoch 1380: 29.348904549944596\n",
            "Cost after epoch 1390: 29.33722970322284\n",
            "Cost after epoch 1400: 29.340147486601175\n",
            "Cost after epoch 1410: 29.333961273416683\n",
            "Cost after epoch 1420: 29.335562917946294\n",
            "Cost after epoch 1430: 29.33091885737228\n",
            "Cost after epoch 1440: 29.331025439937605\n",
            "Cost after epoch 1450: 29.324853060546427\n",
            "Cost after epoch 1460: 29.323245555207336\n",
            "Cost after epoch 1470: 29.319198898607592\n",
            "Cost after epoch 1480: 29.31320534693979\n",
            "Cost after epoch 1490: 29.3236343593064\n",
            "Cost after epoch 1500: 29.314092899376902\n",
            "Cost after epoch 1510: 29.310074586010185\n",
            "Cost after epoch 1520: 29.30757797113861\n",
            "Cost after epoch 1530: 29.307838791608493\n",
            "Cost after epoch 1540: 29.30174784028382\n",
            "Cost after epoch 1550: 29.30166211175085\n",
            "Cost after epoch 1560: 29.301766878896206\n",
            "Cost after epoch 1570: 29.286638012408126\n",
            "Cost after epoch 1580: 29.288090393977182\n",
            "Cost after epoch 1590: 29.295666269436136\n",
            "Cost after epoch 1600: 29.29328480954389\n",
            "Cost after epoch 1610: 29.285770554220424\n",
            "Cost after epoch 1620: 29.293736333558535\n",
            "Cost after epoch 1630: 29.286849493065734\n",
            "Cost after epoch 1640: 29.27802309647567\n",
            "Cost after epoch 1650: 29.287962697648418\n",
            "Cost after epoch 1660: 29.28007018520228\n",
            "Cost after epoch 1670: 29.278831828222337\n",
            "Cost after epoch 1680: 29.27892272302641\n",
            "Cost after epoch 1690: 29.283953301976986\n",
            "Cost after epoch 1700: 29.277043936546495\n",
            "Cost after epoch 1710: 29.272321972493184\n",
            "Cost after epoch 1720: 29.274572734608043\n",
            "Cost after epoch 1730: 29.285494098570094\n",
            "Cost after epoch 1740: 29.284599619391777\n",
            "Cost after epoch 1750: 29.287379934057654\n",
            "Cost after epoch 1760: 29.278002388659928\n",
            "Cost after epoch 1770: 29.283654262520297\n",
            "Cost after epoch 1780: 29.288315018080745\n",
            "Cost after epoch 1790: 29.28911226968118\n",
            "Cost after epoch 1800: 29.29412743243868\n",
            "Cost after epoch 1810: 29.295933418171746\n",
            "Cost after epoch 1820: 29.294117170475516\n",
            "Cost after epoch 1830: 29.301588843721497\n",
            "Cost after epoch 1840: 29.309660832895403\n",
            "Cost after epoch 1850: 29.30898532494162\n",
            "Cost after epoch 1860: 29.307837494474036\n",
            "Cost after epoch 1870: 29.318085021692603\n",
            "Cost after epoch 1880: 29.32410740037165\n",
            "Cost after epoch 1890: 29.321318255321746\n",
            "Cost after epoch 1900: 29.332120862228866\n",
            "Cost after epoch 1910: 29.338164337771367\n",
            "Cost after epoch 1920: 29.336457572488435\n",
            "Cost after epoch 1930: 29.347522746578964\n",
            "Cost after epoch 1940: 29.346203542201515\n",
            "Cost after epoch 1950: 29.35034093203797\n",
            "Cost after epoch 1960: 29.354251710917023\n",
            "Cost after epoch 1970: 29.352474771544834\n",
            "Cost after epoch 1980: 29.353293686688172\n",
            "Cost after epoch 1990: 29.35560035712254\n",
            "Cost after epoch 2000: 29.369454816354366\n",
            "Cost after epoch 2010: 29.363609396023524\n",
            "Cost after epoch 2020: 29.36676087559203\n",
            "Cost after epoch 2030: 29.36559786607041\n",
            "Cost after epoch 2040: 29.36441536244135\n",
            "Cost after epoch 2050: 29.359988067796678\n",
            "Cost after epoch 2060: 29.358924902672516\n",
            "Cost after epoch 2070: 29.366212991037198\n",
            "Cost after epoch 2080: 29.35768371226928\n",
            "Cost after epoch 2090: 29.363769131030523\n",
            "Cost after epoch 2100: 29.35908585967898\n",
            "Cost after epoch 2110: 29.348436535263506\n",
            "Cost after epoch 2120: 29.351776260087576\n",
            "Cost after epoch 2130: 29.35367233275101\n",
            "Cost after epoch 2140: 29.35249486899724\n",
            "Cost after epoch 2150: 29.344478348274375\n",
            "Cost after epoch 2160: 29.332513571491525\n",
            "Cost after epoch 2170: 29.333590765442587\n",
            "Cost after epoch 2180: 29.33047094947615\n",
            "Cost after epoch 2190: 29.3282065525949\n",
            "Cost after epoch 2200: 29.324357627194438\n",
            "Cost after epoch 2210: 29.32620804191565\n",
            "Cost after epoch 2220: 29.32151007165276\n",
            "Cost after epoch 2230: 29.312398494121858\n",
            "Cost after epoch 2240: 29.314187227097506\n",
            "Cost after epoch 2250: 29.304234900825627\n",
            "Cost after epoch 2260: 29.295534881833394\n",
            "Cost after epoch 2270: 29.296932871224804\n",
            "Cost after epoch 2280: 29.287677499713368\n",
            "Cost after epoch 2290: 29.288149835676336\n",
            "Cost after epoch 2300: 29.28632782022315\n",
            "Cost after epoch 2310: 29.27692903338862\n",
            "Cost after epoch 2320: 29.280059754326356\n",
            "Cost after epoch 2330: 29.27826142519068\n",
            "Cost after epoch 2340: 29.267742807199873\n",
            "Cost after epoch 2350: 29.270039125442224\n",
            "Cost after epoch 2360: 29.265306736057873\n",
            "Cost after epoch 2370: 29.25801974431291\n",
            "Cost after epoch 2380: 29.263027431064625\n",
            "Cost after epoch 2390: 29.265982115112735\n",
            "Cost after epoch 2400: 29.253944625554166\n",
            "Cost after epoch 2410: 29.249991267994126\n",
            "Cost after epoch 2420: 29.250815148055107\n",
            "Cost after epoch 2430: 29.25386168774164\n",
            "Cost after epoch 2440: 29.251976917047728\n",
            "Cost after epoch 2450: 29.255493503540375\n",
            "Cost after epoch 2460: 29.24858026402377\n",
            "Cost after epoch 2470: 29.24894349652584\n",
            "Cost after epoch 2480: 29.244830546235473\n",
            "Cost after epoch 2490: 29.24892905162172\n",
            "Cost after epoch 2500: 29.24669913598492\n",
            "Cost after epoch 2510: 29.24485726369197\n",
            "Cost after epoch 2520: 29.25061668420737\n",
            "Cost after epoch 2530: 29.246223658094493\n",
            "Cost after epoch 2540: 29.250312434518122\n",
            "Cost after epoch 2550: 29.25168652131978\n",
            "Cost after epoch 2560: 29.2444340835743\n",
            "Cost after epoch 2570: 29.24167972786577\n",
            "Cost after epoch 2580: 29.245022735216196\n",
            "Cost after epoch 2590: 29.246589283449538\n",
            "Cost after epoch 2600: 29.24672027150944\n",
            "Cost after epoch 2610: 29.244453055344827\n",
            "Cost after epoch 2620: 29.24509450804636\n",
            "Cost after epoch 2630: 29.250084962719352\n",
            "Cost after epoch 2640: 29.249096885394437\n",
            "Cost after epoch 2650: 29.249066995361375\n",
            "Cost after epoch 2660: 29.240780168522154\n",
            "Cost after epoch 2670: 29.24420008044151\n",
            "Cost after epoch 2680: 29.244687858920095\n",
            "Cost after epoch 2690: 29.247023140661145\n",
            "Cost after epoch 2700: 29.24020185859922\n",
            "Cost after epoch 2710: 29.238778896696335\n",
            "Cost after epoch 2720: 29.24330146376707\n",
            "Cost after epoch 2730: 29.242583006482196\n",
            "Cost after epoch 2740: 29.235941362076904\n",
            "Cost after epoch 2750: 29.240497108472667\n",
            "Cost after epoch 2760: 29.230453569346984\n",
            "Cost after epoch 2770: 29.23252845156356\n",
            "Cost after epoch 2780: 29.23419828985928\n",
            "Cost after epoch 2790: 29.228743470095704\n",
            "Cost after epoch 2800: 29.22960804884494\n",
            "Cost after epoch 2810: 29.22304500017998\n",
            "Cost after epoch 2820: 29.225312240897264\n",
            "Cost after epoch 2830: 29.215113241181545\n",
            "Cost after epoch 2840: 29.21790742432239\n",
            "Cost after epoch 2850: 29.2210739434633\n",
            "Cost after epoch 2860: 29.211832709398095\n",
            "Cost after epoch 2870: 29.213188930070544\n",
            "Cost after epoch 2880: 29.208190250262724\n",
            "Cost after epoch 2890: 29.206369792894964\n",
            "Cost after epoch 2900: 29.20489318660579\n",
            "Cost after epoch 2910: 29.200545529741152\n",
            "Cost after epoch 2920: 29.199490409696992\n",
            "Cost after epoch 2930: 29.195828487391566\n",
            "Cost after epoch 2940: 29.196377992123438\n",
            "Cost after epoch 2950: 29.190085354342926\n",
            "Cost after epoch 2960: 29.186440658192005\n",
            "Cost after epoch 2970: 29.18057739672949\n",
            "Cost after epoch 2980: 29.17821831867216\n",
            "Cost after epoch 2990: 29.18375735592838\n",
            "Cost after epoch 3000: 29.18200532869163\n",
            "Cost after epoch 3010: 29.17334684075614\n",
            "Cost after epoch 3020: 29.169738671668906\n",
            "Cost after epoch 3030: 29.17128180318592\n",
            "Cost after epoch 3040: 29.16783925109954\n",
            "Cost after epoch 3050: 29.168368531922752\n",
            "Cost after epoch 3060: 29.166337359275584\n",
            "Cost after epoch 3070: 29.167802547366577\n",
            "Cost after epoch 3080: 29.162412041150066\n",
            "Cost after epoch 3090: 29.163363075841964\n",
            "Cost after epoch 3100: 29.156024726569576\n",
            "Cost after epoch 3110: 29.159292310899787\n",
            "Cost after epoch 3120: 29.158831924034335\n",
            "Cost after epoch 3130: 29.159655588342893\n",
            "Cost after epoch 3140: 29.15774557292055\n",
            "Cost after epoch 3150: 29.15452895460279\n",
            "Cost after epoch 3160: 29.15061028113502\n",
            "Cost after epoch 3170: 29.15028076358028\n",
            "Cost after epoch 3180: 29.150070911108394\n",
            "Cost after epoch 3190: 29.143591380218062\n",
            "Cost after epoch 3200: 29.14700566818216\n",
            "Cost after epoch 3210: 29.145371664357487\n",
            "Cost after epoch 3220: 29.145061319653834\n",
            "Cost after epoch 3230: 29.143917684601092\n",
            "Cost after epoch 3240: 29.1498703943934\n",
            "Cost after epoch 3250: 29.149504858303903\n",
            "Cost after epoch 3260: 29.145019411797122\n",
            "Cost after epoch 3270: 29.14438150967704\n",
            "Cost after epoch 3280: 29.14443194327989\n",
            "Cost after epoch 3290: 29.152910898300668\n",
            "Cost after epoch 3300: 29.150658064301375\n",
            "Cost after epoch 3310: 29.15039424008311\n",
            "Cost after epoch 3320: 29.149479564465484\n",
            "Cost after epoch 3330: 29.14589246802133\n",
            "Cost after epoch 3340: 29.15493276070493\n",
            "Cost after epoch 3350: 29.149126578167216\n",
            "Cost after epoch 3360: 29.14553845431703\n",
            "Cost after epoch 3370: 29.150810832704018\n",
            "Cost after epoch 3380: 29.156691633978536\n",
            "Cost after epoch 3390: 29.1522473616526\n",
            "Cost after epoch 3400: 29.1578727087227\n",
            "Cost after epoch 3410: 29.153879574675482\n",
            "Cost after epoch 3420: 29.15803856222905\n",
            "Cost after epoch 3430: 29.156352216806134\n",
            "Cost after epoch 3440: 29.160844590870486\n",
            "Cost after epoch 3450: 29.157765452160827\n",
            "Cost after epoch 3460: 29.16222260216159\n",
            "Cost after epoch 3470: 29.16045122617626\n",
            "Cost after epoch 3480: 29.163178888969558\n",
            "Cost after epoch 3490: 29.162826330100117\n",
            "Cost after epoch 3500: 29.162225010301555\n",
            "Cost after epoch 3510: 29.167939115041367\n",
            "Cost after epoch 3520: 29.167688880342194\n",
            "Cost after epoch 3530: 29.164742657237273\n",
            "Cost after epoch 3540: 29.167686978189607\n",
            "Cost after epoch 3550: 29.17365691573427\n",
            "Cost after epoch 3560: 29.168792865661494\n",
            "Cost after epoch 3570: 29.16456784248167\n",
            "Cost after epoch 3580: 29.169935234764587\n",
            "Cost after epoch 3590: 29.17103289570358\n",
            "Cost after epoch 3600: 29.171324933335175\n",
            "Cost after epoch 3610: 29.164973586813094\n",
            "Cost after epoch 3620: 29.16988485956171\n",
            "Cost after epoch 3630: 29.17411726801636\n",
            "Cost after epoch 3640: 29.17221564493521\n",
            "Cost after epoch 3650: 29.17509696624449\n",
            "Cost after epoch 3660: 29.173165122770627\n",
            "Cost after epoch 3670: 29.17356582556683\n",
            "Cost after epoch 3680: 29.172297024337688\n",
            "Cost after epoch 3690: 29.173467439973244\n",
            "Cost after epoch 3700: 29.17276683322616\n",
            "Cost after epoch 3710: 29.170490014013527\n",
            "Cost after epoch 3720: 29.173306480335206\n",
            "Cost after epoch 3730: 29.17084475770124\n",
            "Cost after epoch 3740: 29.16525034142929\n",
            "Cost after epoch 3750: 29.171524421078683\n",
            "Cost after epoch 3760: 29.16271822871722\n",
            "Cost after epoch 3770: 29.162646334076676\n",
            "Cost after epoch 3780: 29.167852508178946\n",
            "Cost after epoch 3790: 29.167916537573163\n",
            "Cost after epoch 3800: 29.163645548752665\n",
            "Cost after epoch 3810: 29.160457215823897\n",
            "Cost after epoch 3820: 29.160384338630333\n",
            "Cost after epoch 3830: 29.162859120935565\n",
            "Cost after epoch 3840: 29.159476234873935\n",
            "Cost after epoch 3850: 29.15937116103287\n",
            "Cost after epoch 3860: 29.154555712884108\n",
            "Cost after epoch 3870: 29.154719416093904\n",
            "Cost after epoch 3880: 29.155783517765133\n",
            "Cost after epoch 3890: 29.14943340132625\n",
            "Cost after epoch 3900: 29.149717089208853\n",
            "Cost after epoch 3910: 29.14820135061815\n",
            "Cost after epoch 3920: 29.15006511720165\n",
            "Cost after epoch 3930: 29.149810708863104\n",
            "Cost after epoch 3940: 29.14134801609315\n",
            "Cost after epoch 3950: 29.13905565463159\n",
            "Cost after epoch 3960: 29.137785635025242\n",
            "Cost after epoch 3970: 29.131175954822755\n",
            "Cost after epoch 3980: 29.137807977329956\n",
            "Cost after epoch 3990: 29.13956977901614\n",
            "Cost after epoch 4000: 29.12938646091699\n",
            "Cost after epoch 4010: 29.12875454573363\n",
            "Cost after epoch 4020: 29.123137521931294\n",
            "Cost after epoch 4030: 29.128978430610832\n",
            "Cost after epoch 4040: 29.12328885070483\n",
            "Cost after epoch 4050: 29.123459853021917\n",
            "Cost after epoch 4060: 29.126187459433364\n",
            "Cost after epoch 4070: 29.117753940096193\n",
            "Cost after epoch 4080: 29.119431906932935\n",
            "Cost after epoch 4090: 29.1138571929774\n",
            "Cost after epoch 4100: 29.117220057525728\n",
            "Cost after epoch 4110: 29.110283667150824\n",
            "Cost after epoch 4120: 29.113836879993826\n",
            "Cost after epoch 4130: 29.109621051930446\n",
            "Cost after epoch 4140: 29.108144358465157\n",
            "Cost after epoch 4150: 29.10661709129542\n",
            "Cost after epoch 4160: 29.105861449401075\n",
            "Cost after epoch 4170: 29.103697108244415\n",
            "Cost after epoch 4180: 29.099019788285688\n",
            "Cost after epoch 4190: 29.0966055146257\n",
            "Cost after epoch 4200: 29.094183901795397\n",
            "Cost after epoch 4210: 29.096036869297734\n",
            "Cost after epoch 4220: 29.093252014956953\n",
            "Cost after epoch 4230: 29.093035678104805\n",
            "Cost after epoch 4240: 29.092443518693884\n",
            "Cost after epoch 4250: 29.089905415293718\n",
            "Cost after epoch 4260: 29.090227540161774\n",
            "Cost after epoch 4270: 29.089029178260457\n",
            "Cost after epoch 4280: 29.08995266516002\n",
            "Cost after epoch 4290: 29.08729825713491\n",
            "Cost after epoch 4300: 29.085528081613262\n",
            "Cost after epoch 4310: 29.082281870274258\n",
            "Cost after epoch 4320: 29.078400588717432\n",
            "Cost after epoch 4330: 29.077142460227282\n",
            "Cost after epoch 4340: 29.07535654684186\n",
            "Cost after epoch 4350: 29.073917367904592\n",
            "Cost after epoch 4360: 29.076396852457428\n",
            "Cost after epoch 4370: 29.075099722073904\n",
            "Cost after epoch 4380: 29.07084579957678\n",
            "Cost after epoch 4390: 29.07125474544015\n",
            "Cost after epoch 4400: 29.070837620336775\n",
            "Cost after epoch 4410: 29.065929568419406\n",
            "Cost after epoch 4420: 29.068344817660126\n",
            "Cost after epoch 4430: 29.06712324788819\n",
            "Cost after epoch 4440: 29.061084760402302\n",
            "Cost after epoch 4450: 29.0649119516888\n",
            "Cost after epoch 4460: 29.065148646127327\n",
            "Cost after epoch 4470: 29.06053693616841\n",
            "Cost after epoch 4480: 29.064445137100996\n",
            "Cost after epoch 4490: 29.06003785001969\n",
            "Cost after epoch 4500: 29.05727105219529\n",
            "Cost after epoch 4510: 29.054374879881763\n",
            "Cost after epoch 4520: 29.0541310731506\n",
            "Cost after epoch 4530: 29.05808856389156\n",
            "Cost after epoch 4540: 29.05321595677922\n",
            "Cost after epoch 4550: 29.054823826583775\n",
            "Cost after epoch 4560: 29.04997526934696\n",
            "Cost after epoch 4570: 29.055555080290663\n",
            "Cost after epoch 4580: 29.05466625907063\n",
            "Cost after epoch 4590: 29.051905121572158\n",
            "Cost after epoch 4600: 29.051287033345034\n",
            "Cost after epoch 4610: 29.046260573586313\n",
            "Cost after epoch 4620: 29.049432719953018\n",
            "Cost after epoch 4630: 29.047799602008254\n",
            "Cost after epoch 4640: 29.047004447828307\n",
            "Cost after epoch 4650: 29.044160708820574\n",
            "Cost after epoch 4660: 29.04717871362098\n",
            "Cost after epoch 4670: 29.044585155462514\n",
            "Cost after epoch 4680: 29.047996818391077\n",
            "Cost after epoch 4690: 29.046895237840587\n",
            "Cost after epoch 4700: 29.045040424531262\n",
            "Cost after epoch 4710: 29.04169015456691\n",
            "Cost after epoch 4720: 29.045184751964044\n",
            "Cost after epoch 4730: 29.044272587793174\n",
            "Cost after epoch 4740: 29.047495584126825\n",
            "Cost after epoch 4750: 29.044048401182142\n",
            "Cost after epoch 4760: 29.040921971831654\n",
            "Cost after epoch 4770: 29.040220157891902\n",
            "Cost after epoch 4780: 29.04198753661374\n",
            "Cost after epoch 4790: 29.041870482837428\n",
            "Cost after epoch 4800: 29.044611156391152\n",
            "Cost after epoch 4810: 29.042200595956764\n",
            "Cost after epoch 4820: 29.040876576202848\n",
            "Cost after epoch 4830: 29.0443222103295\n",
            "Cost after epoch 4840: 29.0430579098788\n",
            "Cost after epoch 4850: 29.044110041188702\n",
            "Cost after epoch 4860: 29.041084286839176\n",
            "Cost after epoch 4870: 29.042364207193295\n",
            "Cost after epoch 4880: 29.04513791038958\n",
            "Cost after epoch 4890: 29.04207839519886\n",
            "Cost after epoch 4900: 29.040414880624446\n",
            "Cost after epoch 4910: 29.046830744732347\n",
            "Cost after epoch 4920: 29.042149836146123\n",
            "Cost after epoch 4930: 29.04426345175125\n",
            "Cost after epoch 4940: 29.042097471710132\n",
            "Cost after epoch 4950: 29.044078366352075\n",
            "Cost after epoch 4960: 29.04757080813306\n",
            "Cost after epoch 4970: 29.046689941540183\n",
            "Cost after epoch 4980: 29.04439222403056\n",
            "Cost after epoch 4990: 29.045338248757083\n",
            "training time: 0:01:40.219891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB02TbnsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AvOZrjhq7A_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b506e178-9d57-4a88-8fc9-19db7093d3d3"
      },
      "source": [
        "#1D array to 2D array\n",
        "\n",
        "X_test = np.arange(vocab_size)\n",
        "print(X_test)\n",
        "X_test = np.expand_dims(X_test, axis=0)\n",
        "print(X_test)\n",
        "softmax_test, _ = forward_propagation(X_test, paras)\n",
        "top_sorted_inds = np.argsort(softmax_test, axis=0)[-4:,:]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117]\n",
            "[[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            "  108 109 110 111 112 113 114 115 116 117]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCDtNMn5vgzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a1bbb759-6f6b-4a40-8f78-8a30e52a83da"
      },
      "source": [
        "X_exp = list(id_to_word.keys())\n",
        "X_exp = np.array(X_exp)\n",
        "X_exp = np.expand_dims(X_exp, axis=0)\n",
        "\n",
        "ind_to_word_vecs(X_exp,paras).T[0]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.55351379,  3.7930839 ,  1.68615232,  0.23145101,  0.28906618,\n",
              "        2.27142193, -2.72098571, -0.50286874, -1.1297538 ,  1.01788925,\n",
              "       -0.77028899,  0.85433424, -1.67582469, -1.19665202, -3.25471564,\n",
              "        1.84584622,  1.03170271, -0.88837627, -2.7188877 , -0.45217928,\n",
              "       -2.50826618,  3.03991568, -3.90669957,  1.52864703,  1.92405278,\n",
              "        0.8890996 , -1.63507612, -2.87415893,  0.73642418,  1.20732687,\n",
              "        0.52745946,  1.61739464, -1.21995196, -1.01215976, -5.32724741,\n",
              "        0.6869588 ,  0.49148379, -2.11589455,  0.19249512,  2.27547965,\n",
              "        0.66794672,  0.32678282,  0.59303174, -2.09618367, -0.1593979 ,\n",
              "        0.92962558,  0.58371352,  0.82243479, -0.11705163, -2.48658608,\n",
              "        1.60951648, -0.02943369,  0.42942248,  1.60029597, -0.24124696,\n",
              "        4.34274007, -0.48625728,  3.12085294, -4.49286169, -1.66652249,\n",
              "       -1.56906591,  0.57102377,  0.31435628, -2.10956287, -1.8562644 ,\n",
              "        3.53226825,  0.16354489, -1.74327582, -2.58314706,  0.82471282,\n",
              "       -0.36091945,  0.79500683, -0.68025635,  2.95171103, -0.05966265,\n",
              "        3.58810481,  0.12029144,  1.96363654, -1.13944118,  0.63683838,\n",
              "       -1.20980384,  0.38317364,  0.67690656, -1.33690305, -1.22495437,\n",
              "        1.98774898,  0.85460412, -1.38342066,  1.20441803,  5.80367009,\n",
              "        1.87525048, -2.66719461, -0.6338646 , -2.54549979,  3.17273253,\n",
              "        1.34427573,  2.12859171, -1.54856966,  3.04506648, -4.84471705])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7YcLMlJrBt_",
        "colab_type": "code",
        "outputId": "d9043fd6-4085-4f3e-efd2-94dd164643b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2023
        }
      },
      "source": [
        "for input_ind in range(vocab_size):\n",
        "    input_word = id_to_word[input_ind]\n",
        "    output_words = [id_to_word[output_ind] for output_ind in top_sorted_inds[::-1, input_ind]]\n",
        "    print(\"{}'s neighbor words: {}\".format(input_word, output_words))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "basic's neighbor words: ['that', 'a', 'government', 'americans']\n",
            "values's neighbor words: ['of', 'for', 'interests', 'the']\n",
            "families's neighbor words: ['new', 'of', 'our', 'advantage']\n",
            "made's neighbor words: ['great', 'this', 'economic', 'principles']\n",
            "hereby's neighbor words: ['government', 'want', 'pledge', 'this']\n",
            "energy's neighbor words: ['science', 'infrastructure', 'education', 'country']\n",
            "in's neighbor words: ['times', 'bad', 'investment', 'our']\n",
            "with's neighbor words: ['retirement', 'care', 'health', 'new']\n",
            "advantage's neighbor words: ['opportunities', 'americans', 'take', 'of']\n",
            "and's neighbor words: ['the', 'in', 'of', 'that']\n",
            "is's neighbor words: ['make', 'and', 'to', 'time']\n",
            "only's neighbor words: ['take', 'but', '21st', 'if']\n",
            "american's neighbor words: ['make', 'for', 'real', 'dream']\n",
            "security's neighbor words: ['especially', 'health', 'retirement', 'care']\n",
            "work's neighbor words: ['have', 'chance', 'willing', 'everyone']\n",
            "stands's neighbor words: ['the', 'to', 'that', 'for']\n",
            "invisible's neighbor words: ['democratic', 'have', 'been', 'never']\n",
            "more's neighbor words: ['fair', 'competitive', 'pillars', 'of']\n",
            "them's neighbor words: ['need', 'real', 'dream', 'again']\n",
            "most's neighbor words: ['god', 'their', 'make', 'given']\n",
            "around's neighbor words: ['americans', 'platform', 'all', 'hearings']\n",
            "will's neighbor words: ['americans', 'allow', 'all', 'fair']\n",
            "party's neighbor words: ['time', 'democratic', 'it', 'is']\n",
            "economic's neighbor words: ['made', 'principles', 'basic', 'belief']\n",
            "pillars's neighbor words: ['more', 'these', 'as', 'for']\n",
            "everyone's neighbor words: ['work', 'people', 'gives', 'willing']\n",
            "interests's neighbor words: ['people', 'hopes', 'values', 'working']\n",
            "as's neighbor words: ['of', 'for', 'interests', 'democrats']\n",
            "hearings's neighbor words: ['country', 'in', 'our', 'times']\n",
            "competitive's neighbor words: ['economy', 'more', 'fair', 'a']\n",
            "compete's neighbor words: ['in', 'especially', 'investment', 'can']\n",
            "pledge's neighbor words: ['led', 'hereby', 'we', 'government']\n",
            "take's neighbor words: ['the', 'approach', 'all', 'advantage']\n",
            "obama's neighbor words: ['out', 'by', 'looks', 'led']\n",
            "their's neighbor words: ['potential', 'given', 'god', 'most']\n",
            "democratic's neighbor words: ['is', 'invisible', 'party', 'it']\n",
            "hopes's neighbor words: ['interests', 'up', 'values', 'a']\n",
            "the's neighbor words: ['and', 'of', 'to', 'in']\n",
            "democrats's neighbor words: ['we', 'as', 'opportunity', 'these']\n",
            "god's neighbor words: ['in', 'especially', 'can', 'potential']\n",
            "great's neighbor words: ['this', 'compete', 'want', 'can']\n",
            "these's neighbor words: ['pillars', 'see', 'as', 'democrats']\n",
            "care's neighbor words: ['and', 'economy', 'retirement', 'the']\n",
            "opportunities's neighbor words: ['new', 'of', 'our', 'advantage']\n",
            "who's neighbor words: ['work', 'people', 'gives', 'willing']\n",
            "science's neighbor words: ['of', 'education', 'energy', 'the']\n",
            "this's neighbor words: ['we', 'great', 'can', 'belief']\n",
            "education's neighbor words: ['a', 'them', 'need', 'for']\n",
            "era's neighbor words: ['new', 'of', 'our', 'advantage']\n",
            "new's neighbor words: ['that', 'era', 'opportunities', 'health']\n",
            "hard's neighbor words: ['to', 'is', 'will', 'willing']\n",
            "but's neighbor words: ['we', 'if', '21st', 'century']\n",
            "it's neighbor words: ['to', 'is', 'will', 'willing']\n",
            "that's neighbor words: ['for', 'all', 'this', 'country']\n",
            "principles's neighbor words: ['this', 'economic', 'made', 'basic']\n",
            "especially's neighbor words: ['times', 'security', 'help', 'bad']\n",
            "given's neighbor words: ['platform', 'god', 'their', 'potential']\n",
            "have's neighbor words: ['invisible', 'america', 'never', 'been']\n",
            "century's neighbor words: ['if', 'but', 'only', '21st']\n",
            "see's neighbor words: ['the', 'to', 'that', 'for']\n",
            "government's neighbor words: ['barack', 'up', 'led', 'need']\n",
            "21st's neighbor words: ['only', 'century', 'succeed', 'but']\n",
            "allow's neighbor words: ['to', 'is', 'will', 'willing']\n",
            "america's neighbor words: ['been', 'never', 'have', 'work']\n",
            "time's neighbor words: ['the', 'to', 'that', 'for']\n",
            "out's neighbor words: ['in', 'especially', 'can', 'potential']\n",
            "barack's neighbor words: ['looks', 'by', 'led', 'obama']\n",
            "help's neighbor words: ['bad', 'especially', 'retirement', 'security']\n",
            "faithful's neighbor words: ['basic', 'innovative', 'both', 'make']\n",
            "again's neighbor words: ['a', 'them', 'need', 'for']\n",
            "retirement's neighbor words: ['help', 'care', 'security', 'health']\n",
            "working's neighbor words: ['gives', 'interests', 'people', 'working']\n",
            "do's neighbor words: ['in', 'especially', 'investment', 'potential']\n",
            "never's neighbor words: ['to', 'is', 'will', 'willing']\n",
            "fair's neighbor words: ['will', 'more', 'competitive', 'economy']\n",
            "investment's neighbor words: ['country', 'in', 'our', 'times']\n",
            "can's neighbor words: ['succeed', 'compete', 'nation', 'this']\n",
            "want's neighbor words: ['hereby', 'we', 'for', 'great']\n",
            "economy's neighbor words: ['care', 'allow', 'competitive', 'fair']\n",
            "health's neighbor words: ['security', 'with', 'retirement', 'care']\n",
            "infrastructure's neighbor words: ['ladder', 'energy', 'education', 'science']\n",
            "people's neighbor words: ['the', 'and', 'everyone', 'interests']\n",
            "real's neighbor words: ['again', 'dream', 'them', 'american']\n",
            "up's neighbor words: ['hopes', 'stands', 'government', 'democrats']\n",
            "approach's neighbor words: ['is', 'invisible', 'it', 'party']\n",
            "need's neighbor words: ['that', 'a', 'government', 'americans']\n",
            "innovative's neighbor words: ['to', 'is', 'will', 'willing']\n",
            "bad's neighbor words: ['in', 'can', 'especially', 'investment']\n",
            "times's neighbor words: ['our', 'especially', 'bad', 'investment']\n",
            "succeed's neighbor words: ['21st', 'compete', 'can', 'century']\n",
            "led's neighbor words: ['obama', 'barack', 'pledge', 'by']\n",
            "both's neighbor words: ['faithful', 'one', 'innovative', 'real']\n",
            "gives's neighbor words: ['to', 'is', 'will', 'willing']\n",
            "belief's neighbor words: ['great', 'this', 'economic', 'principles']\n",
            "our's neighbor words: ['country', 'energy', 'era', 'opportunities']\n",
            "ladder's neighbor words: ['for', 'opportunity', 'infrastructure', 'science']\n",
            "a's neighbor words: ['we', 'and', 'government', 'one']\n",
            "country's neighbor words: ['our', 'in', 'democrats', 'great']\n",
            "make's neighbor words: ['the', 'of', 'dream', 'american']\n",
            "opportunity's neighbor words: ['democrats', 'ladder', 'made', 'all']\n",
            "looks's neighbor words: ['families', 'barack', 'out', 'obama']\n",
            "dream's neighbor words: ['them', 'real', 'american', 'make']\n",
            "willing's neighbor words: ['hard', 'everyone', 'gives', 'work']\n",
            "nation's neighbor words: ['and', 'economy', 'retirement', 'with']\n",
            "of's neighbor words: ['and', 'opportunities', 'of', 'era']\n",
            "chance's neighbor words: ['the', 'to', 'that', 'for']\n",
            "platform's neighbor words: ['the', 'to', 'that', 'for']\n",
            "reaffirmed's neighbor words: ['that', 'a', 'government', 'americans']\n",
            "been's neighbor words: ['the', 'to', 'that', 'for']\n",
            "one's neighbor words: ['both', 'approach', 'innovative', 'is']\n",
            "all's neighbor words: ['take', 'will', 'allow', 'americans']\n",
            "americans's neighbor words: ['advantage', 'will', 'allow', 'all']\n",
            "we's neighbor words: ['a', 'new', 'government', 'want']\n",
            "to's neighbor words: ['the', 'of', 'american', 'hard']\n",
            "for's neighbor words: ['the', 'that', 'see', 'values']\n",
            "potential's neighbor words: ['hearings', 'platform', 'given', 'god']\n",
            "by's neighbor words: ['that', 'a', 'government', 'americans']\n",
            "if's neighbor words: ['a', 'but', 'century', 'only']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkyt7levrFdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}